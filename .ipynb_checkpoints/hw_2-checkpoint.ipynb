{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics.cluster import contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, linewidth=150, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'countFriends', 'countFollowers', 'boolComments',\n",
       "       'countOwnerPosts', 'countOwnerReposts', 'countPhotos', 'countVideos',\n",
       "       'countLikesPhotoes', 'sex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([df.countFriends, df.countFollowers, df.countOwnerReposts, df.countOwnerReposts, df.countPhotos, df.countVideos]).transpose()\n",
    "y = np.array(df.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where axis 0 columns and 1 rows\n",
    "me = np.mean(X, axis=0) # mean \n",
    "ra = np.ptp(X, axis=0)  # range \n",
    "Y = np.divide(np.subtract(X, me), ra) # normilizad\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "centers = np.array([Y[1, :], Y[52,:]]) # Выюираем рандом\n",
    "n_clusters = len(centers)\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply K-Means (batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К = 5\n",
    "\n",
    "К = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta1: [ -3.49 -42.53 138.92 138.92  10.57  15.04] #element: 317\n",
      "delta2: [  1.62  19.8  -64.66 -64.66  -4.92  -7.  ] #element: 681\n",
      "delta3: [nan nan nan nan nan nan] #element: 0\n",
      "inertia: 117.80346282351572\n",
      "[[123 288]\n",
      " [194 393]]\n",
      " \n",
      "delta1: [ -4.38 -42.64 139.21 139.21   6.41  15.39] #element: 316\n",
      "delta2: [  2.03  19.76 -64.5  -64.5   -2.97  -7.13] #element: 682\n",
      "delta3: [nan nan nan nan nan nan] #element: 0\n",
      "inertia: 118.42685598514242\n",
      "[[123 288]\n",
      " [193 394]]\n",
      " \n",
      "delta1: [ -3.43 -42.66 138.58 138.58  13.07  14.68] #element: 318\n",
      "delta2: [  1.61  19.95 -64.8  -64.8   -6.11  -6.86] #element: 680\n",
      "delta3: [nan nan nan nan nan nan] #element: 0\n",
      "inertia: 118.22005239869996\n",
      "[[123 288]\n",
      " [195 392]]\n",
      " \n",
      "delta1: [ -6.85 -42.41 140.1  140.1    7.2   14.99] #element: 313\n",
      "delta2: [  3.13  19.38 -64.02 -64.02  -3.29  -6.85] #element: 685\n",
      "delta3: [nan nan nan nan nan nan] #element: 0\n",
      "inertia: 119.05297759155808\n",
      "[[123 288]\n",
      " [190 397]]\n",
      " \n",
      "delta1: [ -7.29 -43.14 142.24 142.24   0.08  14.45] #element: 306\n",
      "delta2: [  3.22  19.07 -62.9  -62.9   -0.04  -6.39] #element: 692\n",
      "delta3: [nan nan nan nan nan nan] #element: 0\n",
      "inertia: 120.53919659227275\n",
      "[[120 291]\n",
      " [186 401]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    mbk = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, init=centers)\n",
    "    mbk.fit(Y)  # Compute K-mean\n",
    "    ms = mbk.labels_\n",
    "    \n",
    "    cluster1 = X[np.where(ms==0)]\n",
    "    cluster2 = X[np.where(ms==1)]\n",
    "    cluster3 = X[np.where(ms==2)]\n",
    "    \n",
    "    mc1 = np.mean(cluster1, axis=0)\n",
    "    mc2 = np.mean(cluster2, axis=0)\n",
    "    mc3 = np.mean(cluster3, axis=0)\n",
    "    \n",
    "    #center of class normalize\n",
    "    d1 = 100*(np.divide(np.subtract(mc1, me), me))\n",
    "    d2 = 100*(np.divide(np.subtract(mc2, me), me))\n",
    "    d3 = 100*(np.divide(np.subtract(mc3, me), me))\n",
    "    \n",
    "    \n",
    "    print(\"delta1:\", d1, \"#element:\", cluster1.shape[0]) \n",
    "    print(\"delta2:\", d2, \"#element:\", cluster2.shape[0])\n",
    "    print(\"delta3:\", d3, \"#element:\", cluster3.shape[0]) \n",
    "    print(\"inertia:\", mbk.inertia_) # сумма квадратных ошибок чем меньше чем лучше\n",
    "    cont_tb = contingency_matrix(labels_true=y, labels_pred=ms) #Как на самом деле (строки) и как мой алгоритм (столбцы) \n",
    "    print(cont_tb)\n",
    "    \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta1: [ -6.49 -42.9  140.4  140.4   11.5   14.7 ] #element: 312\n",
      "delta2: [  2.95  19.51 -63.86 -63.86  -5.23  -6.69] #element: 686\n",
      "delta3: [nan nan nan nan nan nan] #element: 0\n",
      "inertia: 119.83708025393467\n",
      "[[123 288]\n",
      " [189 398]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MiniBatchKMeans' object has no attribute 'centers_clusters_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-37fcdfd6e799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mcont_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontingency_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Как на самом деле (строки) и как мой алгоритм (столбцы)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcont_tb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"center{mbk.centers_clusters_}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MiniBatchKMeans' object has no attribute 'centers_clusters_'"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    \n",
    "    mbk = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, init=centers)\n",
    "    mbk.fit(Y)  # Compute K-mean\n",
    "    ms = mbk.labels_\n",
    "    \n",
    "    cluster1 = X[np.where(ms==0)]\n",
    "    cluster2 = X[np.where(ms==1)]\n",
    "    cluster3 = X[np.where(ms==2)]\n",
    "    \n",
    "    mc1 = np.mean(cluster1, axis=0)\n",
    "    mc2 = np.mean(cluster2, axis=0)\n",
    "    mc3 = np.mean(cluster3, axis=0)\n",
    "    \n",
    "    #center of class normalize\n",
    "    d1 = 100*(np.divide(np.subtract(mc1, me), me))\n",
    "    d2 = 100*(np.divide(np.subtract(mc2, me), me))\n",
    "    d3 = 100*(np.divide(np.subtract(mc3, me), me))\n",
    "    \n",
    "    \n",
    "    print(\"delta1:\", d1, \"#element:\", cluster1.shape[0]) \n",
    "    print(\"delta2:\", d2, \"#element:\", cluster2.shape[0])\n",
    "    print(\"delta3:\", d3, \"#element:\", cluster3.shape[0]) \n",
    "    print(\"inertia:\", mbk.inertia_) # сумма квадратных ошибок чем меньше чем лучше\n",
    "    cont_tb = contingency_matrix(labels_true=y, labels_pred=ms) #Как на самом деле (строки) и как мой алгоритм (столбцы) \n",
    "    print(cont_tb)\n",
    "    print(f\"center: {mbk.centers_clusters_}\")\n",
    "    \n",
    "    \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
